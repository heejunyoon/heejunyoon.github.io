<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Heejun Yoon </title> <meta name="author" content="Heejun Yoon"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9C%A8&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://heejunyoon.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Heejun</span> Yoon </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/miscellaneous/">Miscellaneous </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/thumb_thesis-480.webp 480w,/assets/img/publication_preview/thumb_thesis-800.webp 800w,/assets/img/publication_preview/thumb_thesis-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/thumb_thesis.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="thumb_thesis.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="thesis" class="col-sm-8"> <div class="title">A Combined Twin and Single Network for Fast and Robust Inspection of IC Substrates</div> <div class="author"> Heejun Yoon </div> <div class="periodical"> <em>Ewha Womans University</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.riss.kr/link?id=T17053834" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> <a href="/assets/pdf/HJYoon_thesis_published.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/HJYoon_thesis_ppt_v3.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>This thesis explores a novel approach to inspecting IC substrates by integrating twin and single network architectures for fast and accurate defect detection. For inspecting IC substrates, the repetitive nature of the substrates allows comparison-based inspection approaches that detect changed regions between test and reference images. This research proposes a hybrid approach of Combined Twin and Single Network (abbreviated by C-TSNet). We incorporate a single network that is not affected by misalignments and color variations with a twin network, the proposed network achieves robustness to mis-registration while maintaining low computational latency. Additionally, we introduce CC-TSNet, which is extended version of C-TSNet by adding a channel co-attention module to further improve robustness against characteristic differences.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/thumb_ur_demo-480.webp 480w,/assets/img/publication_preview/thumb_ur_demo-800.webp 800w,/assets/img/publication_preview/thumb_ur_demo-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/thumb_ur_demo.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="thumb_ur_demo.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="2023UR" class="col-sm-8"> <div class="title">Personal Mobility Safe Driving System with Knowledge Distillation</div> <div class="author"> Heejun Yoon<sup>*</sup>, Damin Yeom<sup>*</sup>, Soyeon Lee<sup>*</sup>, and Kahyun Lee<sup>†</sup> <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Equal contribution&lt;br&gt;† Corresponding author"> </i> </div> <div class="periodical"> <em>In 2023 IEEE 20th International Conference on Ubiquitous Robots(UR)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/UR57808.2023.10202355" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://ieeexplore.ieee.org/document/10202355" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> <a href="/assets/pdf/UR2023_poster_final.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>The global personal mobility market has been expanding rapidly due to its convenience. However, the rising number of accidents involving personal mobility devices, including falls, collisions, and incidents with moving vehicles or objects, has become a significant concern. In this paper, we propose a deep learning-based safe driving system that integrates both user and road images to address these safety issues. Our system leverages CNN-based models to simultaneously perform the following tasks: 1) detecting if the user is wearing a helmet, 2) ensuring the user is looking ahead, 3) identifying whether the scooter is being ridden on the sidewalk, and 4) recognizing proximity to intersections. These tasks operate in parallel to provide a comprehensive assessment of the driving environment. The system determines the scooter’s final speed by selecting the minimum speed value from all tasks to ensure maximum safety. Additionally, we utilize knowledge distillation techniques to compress the models, enabling real-time inference on edge devices. This approach delivers a fast, efficient, and highly accurate system, specifically tailored to the needs of personal mobility users.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/thumb_IPIU-480.webp 480w,/assets/img/publication_preview/thumb_IPIU-800.webp 800w,/assets/img/publication_preview/thumb_IPIU-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/thumb_IPIU.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="thumb_IPIU.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="2023IPIU" class="col-sm-8"> <div class="title">Action Recognition using 3D Point Cloud from Frequency Modulated Continuous Wave Radar Signals (in Korean)</div> <div class="author"> Heejun Yoon, Jimin Park, and Jeongtae Kim<sup>†</sup> <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="† Corresponding author"> </i> </div> <div class="periodical"> <em>In 2023 Image Processing and Image Understanding(IPIU)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/IPIU2023_HJYoon_final_paper.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/IPIU2023_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>In this paper, we generated three-dimensional point clouds based on Frequency Modulated Continuous Wave (FMCW) radar and performed object motion classification using Support Tensor Machine (STM). 3D Capon Beamforming was applied to the data acquired by the FMCW radar to generate a three-dimensional point cloud, which was then subsampled in half and converted to one-dimensional data to reduce computation. STM was applied to perform motion classification, and the motion was classified with 82% accuracy.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/thumb_IEIE-480.webp 480w,/assets/img/publication_preview/thumb_IEIE-800.webp 800w,/assets/img/publication_preview/thumb_IEIE-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/thumb_IEIE.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="thumb_IEIE.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="2022IEIE" class="col-sm-8"> <div class="title">2-input Deep Learning based Multi-tasking Safe Driving (in Korean)</div> <div class="author"> Heejun Yoon<sup>*</sup>, Damin Yeom<sup>*</sup>, Soyeon Lee<sup>*</sup>, and Kahyun Lee<sup>†</sup> <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Equal contribution&lt;br&gt;† Corresponding author"> </i> </div> <div class="periodical"> <em>In Fall Annual Conference of The Institute of Electronics and Information Engineers (IEIE)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11195420" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Link</a> <a href="/assets/pdf/IEIE_paper.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/presentation_for_IEIEpaper_competition.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>The rapid growth of electric scooter-sharing services has brought personal mobility devices into the spotlight. However, this rise in popularity has been accompanied by increasing public concern over e-scooter accidents. To address these safety challenges, we propose a deep learning-based safe driving system for electric scooters that analyzes both user and road images. Our framework employs CNN-based models to determine whether the user is wearing a helmet or maintaining proper forward vision by analyzing user images. Simultaneously, the system verifies if the scooter is on a designated road and estimates the distance between the user and the nearest pedestrian from road images. Finally, it calculates the scooter’s optimal velocity using the outputs from these models. By leveraging a fast and precise deep learning approach, our system enhances real-time decision-making and provides a high level of confidence in detecting and mitigating multiple hazards simultaneously.</p> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Heejun Yoon. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos taken by me. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>